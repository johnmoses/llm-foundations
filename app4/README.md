# Large Language Model (LLM) Multimodal workflow

## Introduction

This module introduces text, image, and audio processing capabilities into LLM applications. Some of the features we will be covering include:

- Text processing: Uses DialoGPT for conversational AI
- Images: CLIP for image-text understanding + BLIP for image captioning
- Audio processing: Whisper for speech-to-text conversion
- Processing individual modalities independently
- Combining multiple modalities for richer understanding
- Cross-modal integration (e.g., using transcribed audio as text input)

## How to Use

```bash
# Install dependencies
pip install -r requirements.txt

# Quick test
python app.py --quick-test

# Full demo
python app.py --full-demo
```
