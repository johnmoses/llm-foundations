{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfcd882",
   "metadata": {},
   "source": [
    "# Finance LLM Integration Notebook\n",
    "\n",
    "This notebook guides you through generating finance datasets, fine-tuning language models, integrating Milvus for retrieval-augmented generation (RAG), evaluating with ROUGE and LastMile AutoEval, and building a simple web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e67355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install transformers datasets peft sentence-transformers pymilvus torch fastapi uvicorn[standard] reactpy lastmile jupyterlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5fa3b",
   "metadata": {},
   "source": [
    "## Part 1: Dataset Generation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def generate_finance_datasets():\n",
    "    basic_data = [\n",
    "        (\"What is a stock?\", \"A stock represents ownership in a company and a claim on part of its assets and earnings.\"),\n",
    "        (\"Explain compound interest.\", \"Compound interest is interest calculated on the initial principal and also on accumulated interest.\"),\n",
    "        (\"What is a bond?\", \"A bond is a fixed income instrument representing a loan made by an investor to a borrower.\"),\n",
    "        (\"How does inflation affect investments?\", \"Inflation reduces the purchasing power of money, impacting investment returns.\"),\n",
    "        (\"What is diversification?\", \"Diversification is an investment strategy to reduce risk by allocating investments across various assets.\"),\n",
    "    ]\n",
    "    with open(\"finance_basic_finetune.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"instruction\", \"response\"])\n",
    "        writer.writerows(basic_data)\n",
    "\n",
    "    peft_data = [\n",
    "        [\"Stocks are traded on exchanges such as NYSE and NASDAQ.\"],\n",
    "        [\"The Federal Reserve controls monetary policy in the US.\"],\n",
    "        [\"Diversification helps reduce unsystematic risk in portfolios.\"],\n",
    "        [\"ETFs are investment funds traded on stock exchanges.\"],\n",
    "        [\"Credit ratings assess the creditworthiness of borrowers.\"],\n",
    "    ]\n",
    "    with open(\"finance_peft_finetune.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"text\"])\n",
    "        writer.writerows(peft_data)\n",
    "\n",
    "    preference_data = [\n",
    "        (\"What is a stock?\", \n",
    "         \"A stock represents ownership in a company and a claim on its assets and earnings.\",\n",
    "         \"A stock is a type of bond.\"),\n",
    "        (\"Explain compound interest.\", \n",
    "         \"Compound interest is interest on principal and accumulated interest.\",\n",
    "         \"Compound interest is interest only on the principal.\"),\n",
    "        (\"What is diversification?\", \n",
    "         \"Diversification spreads investments to reduce risk.\",\n",
    "         \"Diversification means investing all in one asset.\"),\n",
    "    ]\n",
    "    with open(\"finance_rlhf_preferences.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"prompt\", \"chosen_response\", \"rejected_response\"])\n",
    "        writer.writerows(preference_data)\n",
    "\n",
    "generate_finance_datasets()\n",
    "print(\"Finance datasets generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fee7ca",
   "metadata": {},
   "source": [
    "## Part 2: Dataset Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6803b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "def load_text_dataset_from_csv(csv_path, text_columns, delimiter=\"\\n\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['text'] = df[text_columns].astype(str).agg(delimiter.join, axis=1)\n",
    "    return Dataset.from_pandas(df[['text']])\n",
    "\n",
    "def load_text_dataset_from_txt(txt_path):\n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    return Dataset.from_list([{'text': line} for line in lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876dc98d",
   "metadata": {},
   "source": [
    "## Part 3: Basic Fine-tuning Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59061e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "def basic_fine_tuning(model_name, dataset_path, output_dir='./basic_finetune_results'):\n",
    "    dataset = load_text_dataset_from_csv(dataset_path, ['instruction', 'response'], delimiter=\"\\nAssistant: \")\n",
    "    dataset = dataset.map(lambda x: {'text': f\"Human: {x['text']}\"})\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=1,  # Increase for real training\n",
    "        per_device_train_batch_size=2,\n",
    "        logging_steps=10,\n",
    "        save_steps=50,\n",
    "        evaluation_strategy=\"no\",\n",
    "        save_total_limit=2,\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=100,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    print(f\"Basic fine-tuning done. Model saved at {output_dir}\")\n",
    "\n",
    "# Example call:\n",
    "# basic_fine_tuning(\"meta-llama/Llama-3-8b\", \"finance_basic_finetune.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a8395d",
   "metadata": {},
   "source": [
    "## Part 4: Milvus RAG Setup and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "class MilvusRAG:\n",
    "    def __init__(self, db_path=\"milvus_rag_db.db\", collection_name=\"rag_collection\", embedding_dim=768):\n",
    "        self.client = MilvusClient(db_path)\n",
    "        self.collection_name = collection_name\n",
    "        self.embedding_dim = embedding_dim\n",
    "        if not self.client.has_collection(collection_name):\n",
    "            self.client.create_collection(collection_name, dimension=embedding_dim)\n",
    "        self.document_store = {}\n",
    "\n",
    "    def insert_documents(self, documents):\n",
    "        embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        embeddings = embedder.encode(documents, convert_to_numpy=True).tolist()\n",
    "        res = self.client.insert(self.collection_name, embeddings)\n",
    "        ids = res['ids']\n",
    "        for doc_id, doc_text in zip(ids, documents):\n",
    "            self.document_store[doc_id] = doc_text\n",
    "        self.client.flush(self.collection_name)\n",
    "\n",
    "    def search(self, query, top_k=3):\n",
    "        embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        query_embedding = embedder.encode([query], convert_to_numpy=True).tolist()\n",
    "        results = self.client.search(self.collection_name, query_embedding, limit=top_k)\n",
    "        hits = results[0]\n",
    "        return [self.document_store.get(hit['id'], \"\") for hit in hits]\n",
    "\n",
    "def rag_generate(query, rag_client, llm_model, tokenizer, top_k=3, max_length=200):\n",
    "    retrieved_docs = rag_client.search(query, top_k=top_k)\n",
    "    context = \"\\n\".join(retrieved_docs)\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = llm_model.generate(**inputs, max_length=max_length)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c46b4",
   "metadata": {},
   "source": [
    "## Part 5: ROUGE Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2acc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "def compute_rouge(predictions, references):\n",
    "    rouge = load_metric(\"rouge\")\n",
    "    results = rouge.compute(predictions=predictions, references=references)\n",
    "    print(\"ROUGE scores:\", results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1cca9",
   "metadata": {},
   "source": [
    "## Part 6: LastMile AutoEval Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from lastmile.lib.auto_eval import AutoEval, BuiltinMetrics\n",
    "    LASTMILE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LASTMILE_AVAILABLE = False\n",
    "\n",
    "def setup_lastmile(api_token):\n",
    "    if not LASTMILE_AVAILABLE:\n",
    "        raise ImportError(\"Install lastmile SDK: pip install lastmile\")\n",
    "    client = AutoEval(api_token=api_token)\n",
    "    print(\"Connected to LastMile AutoEval\")\n",
    "    return client\n",
    "\n",
    "def run_lastmile_builtin_eval(client, dataset_path):\n",
    "    dataset_id = client.upload_dataset(file_path=dataset_path, name=\"Eval Dataset\")\n",
    "    results = client.evaluate_data(dataset_id=dataset_id, metrics=[BuiltinMetrics.FAITHFULNESS, BuiltinMetrics.RELEVANCE])\n",
    "    print(\"LastMile built-in evaluation results:\\n\", results.head())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc06a47",
   "metadata": {},
   "source": [
    "## Part 7: Simple Web UI with ReactPy (runs inside Jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reactpy import component, html, run\n",
    "from reactpy.backend.fastapi import configure\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "rag_client = None\n",
    "model = None\n",
    "tokenizer = None\n",
    "\n",
    "@component\n",
    "def ChatApp():\n",
    "    from reactpy import use_state\n",
    "\n",
    "    query, set_query = use_state(\"\")\n",
    "    answer, set_answer = use_state(\"\")\n",
    "    loading, set_loading = use_state(False)\n",
    "\n",
    "    async def on_submit(event):\n",
    "        event.prevent_default()\n",
    "        set_loading(True)\n",
    "        import httpx\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.post(\"http://localhost:8000/generate\", json={\"query\": query})\n",
    "            data = response.json()\n",
    "            set_answer(data.get(\"answer\", \"No answer\"))\n",
    "        set_loading(False)\n",
    "\n",
    "    return html.section(\n",
    "        html.h1(\"Finance Q&A Chatbot\"),\n",
    "        html.form(\n",
    "            html.textarea(\n",
    "                {\"rows\": 4, \"cols\": 60, \"value\": query, \"on_change\": lambda e: set_query(e[\"target\"][\"value\"]), \"placeholder\": \"Ask a finance question...\"}\n",
    "            ),\n",
    "            html.br(),\n",
    "            html.button({\"type\": \"submit\", \"disabled\": loading}, \"Ask\" if not loading else \"Thinking...\"),\n",
    "            on_submit=on_submit,\n",
    "        ),\n",
    "        html.h2(\"Answer:\"),\n",
    "        html.p(answer),\n",
    "    )\n",
    "\n",
    "configure(app, ChatApp)\n",
    "\n",
    "# To run the UI inside this notebook, uncomment below:\n",
    "# run(ChatApp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
